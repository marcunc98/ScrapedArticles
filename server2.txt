FROM LESSON 18.6 - Scrape-Starter

// Parses our HTML and helps us find elements
var cheerio = require("cheerio");
// Makes HTTP request for HTML page
var request = require("request");

// First, tell the console what server.js is doing
console.log("\n***********************************\n" +
            "Grabbing every thread name (title of a reddit thread) and link\n" +
            "from reddit's webdev board:" +
            "\n***********************************\n");

// Making a request for reddit's "webdev" board. The page's HTML is passed as the callback's third argument
request("http://www.thetravelmagazine.net/articles", function(error, response, html) {

  // Load the HTML into cheerio and save it to a variable
  // '$' becomes a shorthand for cheerio's selector commands, much like jQuery's '$'
  var $ = cheerio.load(html);

  // An empty array to save the data that we'll scrape
  var results = [];

  // With cheerio, find each p-tag with the "title" class
  // (i: iterator. element: the current element)
  $(".item-details").each(function(i, element) {

    // Save the text of the element in a "title" variable
    var title = $(element).find("h3").children("a").text();

    // In the currently selected element, look at its child elements (i.e., its a-tags),
    // then save the values for any "href" attributes that the child elements may have
    var link = $(element).find("h3").children("a").attr("href");

  // Save the summary data of the .td-excerpt element in a "summary" variable with regex 
  // to remove white space and line indentation
    var summary = $(element).find(".td-excerpt").text().replace(/\s\s+/g,'');
    // Save these results in an object that we'll push into the results array we defined earlier
    results.push({
      title: title,
      link: link,
      summary: summary
    });
  });
//   .split(",")[0].split(" ")[0];
  // Log the results once you've looped through each of the elements found with cheerio
  console.log(results);
});